{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quickstart\n",
    "In this example, we'll build an implicit feedback recommender using the Movielens 100k dataset (http://grouplens.org/datasets/movielens/100k/).\n",
    "\n",
    "The code behind this example is available as a [Jupyter notebook](https://github.com/lyst/lightfm/tree/master/examples/quickstart/quickstart.ipynb)\n",
    "\n",
    "LightFM includes functions for getting and processing this dataset, so obtaining it is quite easy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/theja/miniconda3/envs/datasci-dev/lib/python3.7/site-packages/lightfm/_lightfm_fast.py:9: UserWarning: LightFM was compiled without OpenMP support. Only a single thread will be used.\n",
      "  warnings.warn('LightFM was compiled without OpenMP support. '\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from lightfm.datasets import fetch_movielens\n",
    "\n",
    "data = fetch_movielens(min_rating=5.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This downloads the dataset and automatically pre-processes it into sparse matrices suitable for further calculation. In particular, it prepares the sparse user-item matrices, containing positive entries where a user interacted with a product, and zeros otherwise.\n",
    "\n",
    "We have two such matrices, a training and a testing set. Both have around 1000 users and 1700 items. We'll train the model on the train matrix but test it on the test matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<943x1682 sparse matrix of type '<class 'numpy.int32'>'\n",
      "\twith 19048 stored elements in COOrdinate format>\n",
      "<943x1682 sparse matrix of type '<class 'numpy.int32'>'\n",
      "\twith 2153 stored elements in COOrdinate format>\n"
     ]
    }
   ],
   "source": [
    "print(repr(data['train']))\n",
    "print(repr(data['test']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to import the model class to fit the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightfm import LightFM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to use the WARP (Weighted Approximate-Rank Pairwise) model. WARP is an implicit feedback model: all interactions in the training matrix are treated as positive signals, and products that users did not interact with they implicitly do not like. The goal of the model is to score these implicit positives highly while assigining low scores to implicit negatives.\n",
    "\n",
    "Model training is accomplished via SGD (stochastic gradient descent). This means that for every pass through the data --- an epoch --- the model learns to fit the data more and more closely. We'll run it for 30 epochs in this example. We can also run it on multiple cores, so we'll set that to 2. (The dataset in this example is too small for that to make a difference, but it will matter on bigger datasets.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 441 ms, sys: 2.66 ms, total: 443 ms\n",
      "Wall time: 446 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<lightfm.lightfm.LightFM at 0x114e13910>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LightFM(loss='warp')\n",
    "model.fit(data['train'], epochs=30, num_threads=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done! We should now evaluate the model to see how well it's doing. We're most interested in how good the ranking produced by the model is. Precision@k is one suitable metric, expressing the percentage of top k items in the ranking the user has actually interacted with. `lightfm` implements a number of metrics in the `evaluation` module. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from lightfm.evaluation import precision_at_k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll measure precision in both the train and the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Train precision: %.2f\" % precision_at_k(model, data['train'], k=5).mean())\n",
    "# print(\"Test precision: %.2f\" % precision_at_k(model, data['test'], k=5).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unsurprisingly, the model fits the train set better than the test set.\n",
    "\n",
    "For an alternative way of judging the model, we can sample a couple of users and get their recommendations. To make predictions for given user, we pass the id of that user and the ids of all products we want predictions for into the `predict` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_recommendation(model, data, user_ids):\n",
    "    \n",
    "\n",
    "    n_users, n_items = data['train'].shape\n",
    "\n",
    "    for user_id in user_ids:\n",
    "        known_positives = data['item_labels'][data['train'].tocsr()[user_id].indices]\n",
    "        \n",
    "        scores = model.predict(user_id, np.arange(n_items))\n",
    "        top_items = data['item_labels'][np.argsort(-scores)]\n",
    "        \n",
    "        print(\"User %s\" % user_id)\n",
    "        print(\"     Known positives:\")\n",
    "        \n",
    "        for x in known_positives[:3]:\n",
    "            print(\"        %s\" % x)\n",
    "\n",
    "        print(\"     Recommended:\")\n",
    "        \n",
    "        for x in top_items[:3]:\n",
    "            print(\"        %s\" % x)\n",
    "        \n",
    "# sample_recommendation(model, data, [3, 25, 450]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "def all_recommendations(model, data, k=10):\n",
    "    \n",
    "    n_users, n_items = data['train'].shape\n",
    "    rec_list = []\n",
    "    for user_id in np.arange(n_users):\n",
    "        scores = model.predict(user_id, np.arange(n_items))\n",
    "        top_k_items = data['item_labels'][np.argsort(-scores)][:k]\n",
    "        rec_list.append((user_id,top_k_items))\n",
    "    df = pd.DataFrame(data=rec_list,columns=['uid','rec'])\n",
    "    df['pred_time'] = str(datetime.datetime.now())\n",
    "    return df\n",
    "df = all_recommendations(model, data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uid</th>\n",
       "      <th>rec</th>\n",
       "      <th>pred_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[Fargo (1996), Star Wars (1977), Close Shave, ...</td>\n",
       "      <td>2020-09-23 19:41:17.939803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[Dead Man Walking (1995), Contact (1997), Good...</td>\n",
       "      <td>2020-09-23 19:41:17.939803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[Chasing Amy (1997), Fargo (1996), English Pat...</td>\n",
       "      <td>2020-09-23 19:41:17.939803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[G.I. Jane (1997), Evita (1996), Contact (1997...</td>\n",
       "      <td>2020-09-23 19:41:17.939803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[Blade Runner (1982), Casablanca (1942), Raide...</td>\n",
       "      <td>2020-09-23 19:41:17.939803</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   uid                                                rec  \\\n",
       "0    0  [Fargo (1996), Star Wars (1977), Close Shave, ...   \n",
       "1    1  [Dead Man Walking (1995), Contact (1997), Good...   \n",
       "2    2  [Chasing Amy (1997), Fargo (1996), English Pat...   \n",
       "3    3  [G.I. Jane (1997), Evita (1996), Contact (1997...   \n",
       "4    4  [Blade Runner (1982), Casablanca (1942), Raide...   \n",
       "\n",
       "                    pred_time  \n",
       "0  2020-09-23 19:41:17.939803  \n",
       "1  2020-09-23 19:41:17.939803  \n",
       "2  2020-09-23 19:41:17.939803  \n",
       "3  2020-09-23 19:41:17.939803  \n",
       "4  2020-09-23 19:41:17.939803  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:04,  4.20s/it]\n"
     ]
    }
   ],
   "source": [
    "#Send predictions to BigQuery\n",
    "#this assumes the GOOGLE_\n",
    "from google.oauth2 import service_account\n",
    "import pandas_gbq\n",
    "table_id = \"movie_recommendation_service.predicted_movies\"\n",
    "project_id = \"authentic-realm-276822\"\n",
    "credentials = service_account.Credentials.from_service_account_file('model-user.json')\n",
    "pandas_gbq.to_gbq(df, table_id, project_id=project_id, if_exists = 'replace', credentials=credentials)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
